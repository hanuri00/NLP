{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJ9Gfxj3H/Bjp3PfTqnnVE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mwxQHr4oqj9Z"},"outputs":[],"source":["#데이터 없이 NER 모델 학습\n","#Few-shot 개체명 리스트 작성\n","#GPT-3를 사용한 개체명 리스트 확장\n","#GPT-3를 사용한 개체명인식 데이터셋 생성\n","#NER 모델 학습 - huggingface"]},{"cell_type":"code","source":["#Few-shot 개체명 리스트 작성\n","#호텔 도메인\n","#엔티티 클래스는 <hotel name>, <room type>, <person name>, <date>, <hotel supplies>로 총 5개 입니다."],"metadata":{"id":"bHQrL10Zq66p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["real_entities = [\n","    {\n","        'class_name': 'hotel name',\n","        'entity_names': [\n","            'Ritz-Carlton Hotel',\n","            'Marriott',\n","            'The Luxury Collection Hotels & Resorts',\n","            'St Regis Hotels',\n","            'Hyatt'\n","        ]\n","    },\n","\n","    {\n","        'class_name': 'room type',\n","        'entity_names': [\n","            'Single room',\n","            'twin room',\n","            'Double room',\n","            'deluxe room',\n","            'Suites',\n","        ]\n","    },\n","    {\n","        'class_name': 'person name',\n","        'entity_names': [\n","            'Yongsun Yoon',\n","            'Steve Adams',\n","            'Donnie K. Schneider',\n","            'Eleanor Lockhart',\n","            'Jacqueline R. French'\n","        ]\n","    },\n","    {\n","        'class_name': 'date',\n","        'entity_names': [\n","            '3/4/2022',\n","            'November 27th',\n","            'December 15, 2023',\n","            'Feb. 8',\n","            'Saturday, Jul 22'\n","        ]\n","    },\n","    {\n","        'class_name': 'hotel supplies',\n","        'entity_names': [\n","            'shampoo',\n","            'Coffee kit',\n","            'towels',\n","            'Wine glass',\n","            'fan'\n","        ]\n","    }\n","]"],"metadata":{"id":"ebG0YO5FrJUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GPT-3를 사용한 개체명 리스트 확장"],"metadata":{"id":"kiOtb3tQrMI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(prompts, model='text-davinci-003', n=1, max_tokens=512):\n","    response = openai.Completion.create(\n","        model = model,\n","        prompt = prompts,\n","        echo = False,\n","        n = n,\n","        max_tokens = max_tokens,\n","        # stop = '\\n'\n","    )\n","\n","    texts = [c.text.strip() for c in response.choices]\n","    return texts\n","\n","\n","def construct_entity_prompt(class_name, entity_names, k=10):\n","    prompt = f'These are <{class_name}> entity names. Generate {k} new <{class_name}> entity names.\\n\\n'\n","    prompt += 'Entity names:\\n'\n","    for e in entity_names:\n","        prompt += f'- {e}\\n'\n","    prompt += '\\nGenerated names:\\n-'\n","    return prompt\n","\n","\n","def postprocess_entities(synthetic_entities):\n","    processed = []\n","    for ents in synthetic_entities:\n","        ents = f'- {ents}'.split('\\n')\n","        ents = [e.split('- ')[1].strip() for e in ents]\n","        processed += ents\n","    return processed\n","\n","\n","\n","synthetic_entities = []\n","for real_ent in tqdm(real_entities):\n","    class_name, entity_names = real_ent['class_name'], real_ent['entity_names']\n","    prompt = construct_entity_prompt(class_name, entity_names)\n","\n","    syn_entities = generate(prompt, n=10)\n","    syn_entities = postprocess_entities(syn_entities)\n","    syn_entities = list(set(syn_entities))\n","\n","    synthetic_entities.append({'class_name': class_name, 'entity_names': syn_entities})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"id":"7bAo5whprRFt","executionInfo":{"status":"error","timestamp":1691892917654,"user_tz":-540,"elapsed":14,"user":{"displayName":"SukJIn Kim","userId":"17812388049255700295"}},"outputId":"dfe630a8-a4be-405b-92ca-7e170d24d4aa"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-6363f50e9cd2>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0msynthetic_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mreal_ent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_entities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_ent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_ent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_entity_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"]}]},{"cell_type":"code","source":["print(prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"tYOy88JyrRpS","executionInfo":{"status":"error","timestamp":1691893077437,"user_tz":-540,"elapsed":6,"user":{"displayName":"SukJIn Kim","userId":"17812388049255700295"}},"outputId":"b9507002-dc3f-4f14-d634-9fe4c8b4f825"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-02c0b5589e49>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"]}]},{"cell_type":"code","source":["synthertic_entities[-1]"],"metadata":{"id":"G8tSIeHmr5EJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_entities = []\n","for real, synthetic in zip(real_entities, synthetic_entities):\n","    all_entities.append({\n","        'class_name': real['class_name'],\n","        'entity_names': list(set(real['entity_names'] + synthetic['entity_names']))\n","    })"],"metadata":{"id":"N5Hxa8pVseMK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GPT-3를 사용한 개체명인식 데이터셋 생성"],"metadata":{"id":"r4-ms57XsgFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_entities(all_entities, min_k=1, max_k=3):\n","    k = np.random.randint(min_k, max_k+1)\n","    idxs = np.random.choice(range(len(all_entities)), size=k, replace=False)\n","\n","    entities = []\n","    for i in idxs:\n","        ents = all_entities[i]\n","        name = np.random.choice(ents['entity_names'])\n","        entities.append({'class_name': ents['class_name'], 'entity_name': name})\n","\n","    return entities\n","\n","\n","def construct_sentence_prompt(entities, style='dialog'):\n","    prompt = f'Generate a {style} sentence including following entities.\\n\\n'\n","\n","    entities_string = ', '.join([f\"{e['entity_name']}({e['class_name']})\" for e in entities])\n","    prompt += f'Entities: {entities_string}\\n'\n","    prompt += 'Sentence:'\n","    return prompt\n","\n","\n","def construct_labels(generated, entities, class2idx):\n","    labels = [class2idx['outside']] * len(generated)\n","    for ent in entities:\n","        l = class2idx[ent['class_name']]\n","        for span in re.finditer(ent['entity_name'].lower(), generated.lower()):\n","            s, e = span.start(), span.end()\n","            labels[s] = l\n","            labels[s+1:e] = [l+1] * (e-s-1)\n","    return labels\n","\n","\n","class2idx = {e['class_name']: i*2 for i, e in enumerate(all_entities)}\n","class2idx['outside'] = len(class2idx) * 2\n","\n","data = []\n","for _ in tqdm(range(100)):\n","    batch_entities = [sample_entities(all_entities) for _ in range(10)]\n","    batch_prompts = [construct_sentence_prompt(ents) for ents in batch_entities]\n","    batch_generated = generate(batch_prompts, model='text-davinci-002')\n","\n","    for generated, entities in zip(batch_generated, batch_entities):\n","        labels = construct_labels(generated, entities, class2idx)\n","        data.append({'text': generated, 'labels': labels})\n","\n","    time.sleep(10)"],"metadata":{"id":"UlRQBRaHsj0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#NER 모델 학습\n","# Huggingface에 공개된 roberta-base 모델을 Token classification 방법으로 학습"],"metadata":{"id":"MdnxQGrnsmSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LABELS = ['B-HT', 'I-HT', 'B-RT', 'I-RT', 'B-PS', 'I-PS', 'B-DT', 'I-DT', 'B-SP', 'I-SP', 'O']\n","\n","\n","def pad_sequences(seqs, pad_val, max_length):\n","    _max_length = max([len(s) for s in seqs])\n","    max_length = min(max_length, _max_length)\n","\n","    padded_seqs = []\n","    for seq in seqs:\n","        seq = seq[:max_length]\n","        pads = [pad_val] * (max_length - len(seq))\n","        seq = seq + pads\n","        padded_seqs.append(seq)\n","\n","    return padded_seqs\n","\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, data, tokenizer, max_length, split='train'):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.split = split\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        text = item['text']\n","        char_labels = item['labels']\n","\n","        inputs = self.tokenizer(text)\n","        input_ids = inputs.input_ids\n","        attention_mask = inputs.attention_mask\n","\n","        labels = []\n","        for i in range(len(input_ids)):\n","            span = inputs.token_to_chars(i)\n","            if span is None:\n","                labels.append(len(LABELS)-1) # O\n","            else:\n","                labels.append(char_labels[span.start])\n","\n","        return input_ids, attention_mask, labels\n","\n","\n","    def collate_fn(self, batch):\n","        input_ids, attention_mask, labels = zip(*batch)\n","        input_ids = pad_sequences(input_ids, self.tokenizer.pad_token_id, self.max_length)\n","        attention_mask = pad_sequences(attention_mask, 0, self.max_length)\n","        labels = pad_sequences(labels, -100, self.max_length)\n","\n","        return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(labels)\n","\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","\n","rand_idxs = np.random.permutation(range(len(data)))\n","train_idxs = rand_idxs[100:]\n","valid_idxs = rand_idxs[:100]\n","\n","train_data = [data[i] for i in train_idxs]\n","valid_data = [data[i] for i in valid_idxs]\n","\n","train_dataset = Dataset(train_data, tokenizer, 256)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=train_dataset.collate_fn)\n","\n","valid_dataset = Dataset(valid_data, tokenizer, 256)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False, collate_fn=valid_dataset.collate_fn)"],"metadata":{"id":"hmBFXmH3srGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#KLUE 벤치마크 참고\n","#entity F1 / character F1 사용"],"metadata":{"id":"4Q108OIYsvrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, loader, device, outside_weight=0.9):\n","    model.train()\n","\n","    label_weight = torch.ones(model.num_labels)\n","    label_weight[-1] = outside_weight\n","    label_weight = label_weight.to(device)\n","\n","    pbar = tqdm(loader)\n","    for batch in pbar:\n","        batch = [b.to(device) for b in batch]\n","        input_ids, attention_mask, labels = batch\n","\n","        outputs = model(input_ids, attention_mask)\n","        logits = outputs.logits\n","        logits = logits.view(-1, model.num_labels)\n","        labels = labels.view(-1)\n","\n","        loss = F.cross_entropy(logits, labels, weight=label_weight)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        pbar.set_postfix({'loss': loss.item()})\n","\n","\n","def predict(model, loader, device):\n","    model.eval()\n","\n","    total_preds, total_labels = [], []\n","    for batch in tqdm(loader):\n","        batch = [b.to(device) for b in batch]\n","        input_ids, attention_mask, labels = batch\n","        with torch.no_grad():\n","            outputs = model(input_ids, attention_mask, labels=labels)\n","\n","        preds = outputs.logits.argmax(dim=-1)\n","        total_preds += preds.cpu().tolist()\n","        total_labels += labels.cpu().tolist()\n","\n","    return total_preds, total_labels\n","\n","\n","def remove_padding(preds, labels):\n","    removed_preds, removed_labels = [], []\n","    for p, l in zip(preds, labels):\n","        if -100 not in l: continue\n","\n","        idx = l.index(-100)\n","        removed_preds.append(p[:idx])\n","        removed_labels.append(l[:idx])\n","\n","    return removed_preds, removed_labels\n","\n","\n","def entity_f1_func(preds, targets):\n","    preds = [[LABELS[p] for p in pred] for pred in preds]\n","    targets = [[LABELS[t] for t in target] for target in targets]\n","    entity_macro_f1 = ner_f1_score(targets, preds, average=\"macro\", mode=\"strict\", scheme=IOB2)\n","    f1 = entity_macro_f1 * 100.0\n","    return round(f1, 2)\n","\n","def char_f1_func(preds, targets):\n","    label_indices = list(range(len(LABELS)))\n","    preds = list(itertools.chain(*preds))\n","    targets = list(itertools.chain(*targets))\n","    f1 = f1_score(targets, preds, labels=label_indices, average='macro', zero_division=True) * 100.0\n","    return round(f1, 2)\n","\n","\n","def evaluate(model, loader, device):\n","    preds, labels = predict(model, loader, device)\n","    preds, labels = remove_padding(preds, labels)\n","    entity_f1 = entity_f1_func(preds, labels)\n","    char_f1 = char_f1_func(preds, labels)\n","    return entity_f1, char_f1\n","\n","\n","\n","num_labels = len(LABELS)\n","id2label = {i:l for i,l in enumerate(LABELS)}\n","label2id = {l:i for i,l in enumerate(LABELS)}\n","\n","model = AutoModelForTokenClassification.from_pretrained('roberta-base', num_labels=num_labels, id2label=id2label, label2id=label2id)\n","_ = model.train().to('cuda:0')\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n","\n","best_score = 0.\n","for ep in range(5):\n","    train(model, train_loader, 'cuda:0')\n","    entity_f1, char_f1 = evaluate(model, valid_loader, 'cuda:0')\n","    print(f'ep: {ep:02d} | entity f1: {entity_f1:.2f} | char f1: {char_f1:.2f}')\n","\n","    if entity_f1 > best_score:\n","        model.save_pretrained('checkpoint')\n","        tokenizer.save_pretrained('checkpoint')\n","        best_score = entity_f1"],"metadata":{"id":"H_rvw_Qds25g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#5 epoch 학습 결과, 검증 데이터에서 94.83 entity F1, 96.58 character F1의 성능"],"metadata":{"id":"PYBg1clStsQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데스트"],"metadata":{"id":"HWgGIN89s5LM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 새 섹션"],"metadata":{"id":"QvzvRWxdbhfp"}},{"cell_type":"code","source":["nlp = pipeline(task='token-classification', model=\"checkpoint\", aggregation_strategy='simple')\n","sentence = \"Can i make a reservation at the Chosun Hotel on Frbruary 3rd?\"\n","nlp(sentence)\n","\n","sentence = \"i made a reservation for a basis room under Jung Hyung-joon.\"\n","nlp(sentence)\n","\n","sentence = \"Cann I refill the ice cups?\"\n","nlp(sentence)"],"metadata":{"id":"py-vBfWws9ql"},"execution_count":null,"outputs":[]}]}