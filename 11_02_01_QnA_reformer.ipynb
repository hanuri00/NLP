{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDfsKDo+gVUm1ktBY6wWqj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Q&A\n","### Reformer 모델을 활용하여 Q&A 학습 및 예측"],"metadata":{"id":"Vn3rIsoSeFR4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0MIr2EnYY7E"},"outputs":[],"source":["# 필요한 라이브러리 설치 및 import\n","!pip install -q transformers\n","\n","import torch\n","from transformers import ReformerTokenizer, ReformerForQuestionAnswering"]},{"cell_type":"code","source":["# 버전 의존성 문제발생시 특정 버전 설치 필요함.\n","# !pip uninstall torch -y\n","# !pip install torch==1.9.0\n","# !pip install transformers==4.10.0"],"metadata":{"id":"bJPeOlQ6N2z_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 및 토크나이저 초기화\n","tokenizer = ReformerTokenizer.from_pretrained('google/reformer-enwik8')\n","model = ReformerForQuestionAnswering.from_pretrained('google/reformer-enwik8')"],"metadata":{"id":"aiUXoA0aYh2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 문맥(context) 및 질문(question) 정의\n","context = \"The Reformer model is a type of transformer model that is designed to handle long-range dependencies more efficiently. It introduces the use of reversible layers and a locality-sensitive hashing mechanism to reduce memory consumption and improve speed. It has been shown to be effective in various natural language processing tasks including question answering.\"\n","question = \"What is the Reformer model?\""],"metadata":{"id":"sX8wu9q8Opmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 토큰화\n","inputs = tokenizer.encode_plus(question, context, return_tensors='pt')"],"metadata":{"id":"x3Wx1SMQOppc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예측 수행\n","start_logits, end_logits = model(**inputs).logits"],"metadata":{"id":"i4WeJP1MOpsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예측 결과 추출\n","all_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","answer = ' '.join(all_tokens[torch.argmax(start_logits) : torch.argmax(end_logits)+1])"],"metadata":{"id":"rZJKSAhmOpvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예측 결과 출력\n","print(\"Question:\", question)\n","print(\"Answer:\", answer)"],"metadata":{"id":"HUjCP4WWOwwv"},"execution_count":null,"outputs":[]}]}